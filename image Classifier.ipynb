{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c4aeed-87d7-4659-af8a-f886fbd902e4",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "## 1. Setup\n",
    "#### 1.1 Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65efd6b4-bf94-4792-8321-ff6bc6782b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5398617-1e5b-4367-a5a1-7d78793c2dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088820d-7a76-4e68-9525-3ee255263e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2ab8f-c5fc-4dc1-9074-2b579b5ae507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU memory consumption growth (In case GPU is used)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimantal.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071538d-4ed0-42ac-8e00-06a51030bb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1464c5-14b9-4315-ac0c-f059431394a4",
   "metadata": {},
   "source": [
    "#### 1.2 Remove unfit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d54bd-b45b-4c42-8f02-0df284e734b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fad178-a358-4bad-9cfe-56826ef64a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = 'data'\n",
    "data_classes = os.listdir(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a230b3c-fdd5-4377-89ca-67ce54d05d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(data_directory, 'angry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58786f5-c659-4b95-8f22-f177073f8a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_extensions = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21b692-7f4d-4f6c-a2df-5c28db7235f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image_class in data_classes:\n",
    "    for image in os.listdir(os.path.join(data_directory, image_class)):\n",
    "        image_path = os.path.join(data_directory, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path) # Checking whether the image can be loaded into opencv\n",
    "            tip = imghdr.what(image_path) # Getting the image type to filter it afterwards\n",
    "            if tip not in image_extensions:\n",
    "                print('Image not in extensions list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652140c-7b9c-440d-9020-8b6d723c6ff6",
   "metadata": {},
   "source": [
    "#### 1.3 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e8041-567d-4dfa-b41e-32cb41251f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorflow API\n",
    "tf.data.Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7322926-49e2-489f-9770-7f1a05800830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.data.Dataset.list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81195e-b9d0-41f1-b70f-1f13a0239b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d2fdc-76f2-453c-ad1d-5bee62202c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data') # Helper used to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d86d1a-3454-44bb-9eac-f2006cd10205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator() # Converting to iterate the data more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a679311-5b6b-4da4-b79c-6b4961702a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get another batch from the iterator\n",
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497a18d-d338-4d96-88ce-ee4b66e0f132",
   "metadata": {},
   "source": [
    "- Images get automatically resized to `256x256`.\n",
    "- Also sets a batch size (Changeable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca96684-18ee-44d1-9111-0f4201162677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Images represented as numpy arrays\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838cf17-2a1d-4d89-a5cd-f37433b27ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "# CLASS 0: Angry\n",
    "# CLASS 1: Calm\n",
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f19009-8b9d-43b8-86e7-b023e0a9a764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20)) # Used to plot out 4 images\n",
    "for index, img in enumerate(batch[0][:4]):\n",
    "    ax[index].imshow(img.astype(int))\n",
    "    ax[index].title.set_text(batch[1][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4d3a5-23dd-48a6-b21d-b52c348d5f67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Preprocess Data\n",
    "#### 2.1 Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbaad6-9ec8-4258-847a-1de6414fa194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda x, y: (x/255, y)) # Execute a function across the dataset to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bea49-fa17-4017-9c22-8a47340c5766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()[0].max() # The max will be 1 and the min 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc94a23-f312-4b4b-89dc-58314dcc9b9f",
   "metadata": {},
   "source": [
    "#### 2.2 Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06738040-de1d-4daf-b0cc-5133e4ec4a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data) # Number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15d018-1747-4271-bdcf-23e0c6984427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_size = int(len(data)*.7)\n",
    "validation_size = int(len(data)*.2)\n",
    "testing_size = int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc610f4b-85e0-4960-8789-bbfe641c6e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_size + training_size + validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65830372-29d1-4d0d-909c-3b90f9972194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data needs to be shuffled before this (already done in this case)\n",
    "train = data.take(training_size)\n",
    "validation = data.skip(training_size).take(validation_size)\n",
    "testing = data.skip(training_size+validation_size).take(testing_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46455e13-8a26-4e49-b1d1-ad262f9d69a4",
   "metadata": {},
   "source": [
    "## 3. Deep Model\n",
    "#### 3.1 Build the Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d60c4-a574-4ffe-887e-ab4bf8dd95e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9f958-920c-45a2-9ee2-6456af5325f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model = Sequantial([Conv2D, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9527da4-82db-4f03-aa6c-91b0d2c808c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(256, 256, 3))) # 16 filters of 3x3 size stepping every 1 pixel, relu - rectified linear unit\n",
    "model.add(MaxPooling2D()) # Condenses the information (width and height) by taking the max value after the relu activation (goes over a 2x2 region and takes the max)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) # transforms the feature maps into a 1D vector. \n",
    "\n",
    "model.add(Dense(256, activation='relu')) # First Dense layer with 256 neurons (Dense beacause they are fully conencted)\n",
    "model.add(Dense(1, activation='sigmoid')) # sigmoid converts every value to a value between 0-1 (angry or calm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d4432-d666-454e-a83f-85d1fd111c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryFocalCrossentropy(), metrics=['accuracy']) # adam is the optimizer, then the loss function and the metric of evaluation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3da873-c92f-4b67-a7ad-fa516f36ba7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebc120-8572-434e-995c-12791cacbc35",
   "metadata": {},
   "source": [
    "The convolutional layers will scale down data, this can be prevented by adding **padding**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175306e4-c7e3-4cc9-9642-ab65ba828897",
   "metadata": {},
   "source": [
    "#### 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f7f8a-4ca5-4065-8b73-f0b4962c71cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52af31-a603-4435-9852-375899c4e003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d64cd7-9bf5-4c9f-89cf-c86f7ab3a5af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs=20, validation_data=validation, callbacks=[tensorboard_callback]) # epochs is how long training lasts, how many runs the model will go through the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43241195-ef8b-4f75-87b1-695400e60a6a",
   "metadata": {},
   "source": [
    "#### 3.3 Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a92de-665d-4ee4-94ce-554b1d4d5256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c593b-a397-4877-9777-8015f0ff7b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['loss'], color='teal', label='loss')\n",
    "plt.plot(history.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d0719-6f26-421b-aa65-a8fe6f39471f",
   "metadata": {},
   "source": [
    "In the case where the val_loss starts to go up and the loss keeps going down could indicate that the model is overfitting (has a variance problem): in this case the best approach would be regularization, applying some data or change some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc37bc-f71a-4ec1-ad2a-3e7d98e65a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa595c50-1851-454f-8eb2-dbaea55cfb7b",
   "metadata": {},
   "source": [
    "## 4. Evaluate Performance\n",
    "#### 4.1 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3b571-6d15-4630-9db5-baa3efa367b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f12d95-3eed-4ef7-be2d-cbaba3122a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision = Precision()\n",
    "recall = Recall()\n",
    "accuracy = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b368f81-0078-4738-bcb8-cafc68a62d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in testing.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    yhat = model.predict(x)\n",
    "    precision.update_state(y, yhat)\n",
    "    recall.update_state(y, yhat)\n",
    "    accuracy.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318ed65-0af7-4594-846f-a10417593a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Precision: {precision.result().numpy()}, Recall: {recall.result().numpy()}, Accuracy: {accuracy.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10380dc1-e82c-4caf-9bfc-e1461461f78c",
   "metadata": {},
   "source": [
    "#### 4.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e07a1-57e6-4d28-abc5-8bc082a8a042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('calmtest.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # display might be weird beacuse opencv reads it in bgr\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d237f77-25a5-479d-a287-53ea0a8b91a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resized_image = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resized_image.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d4699-e087-4c86-abd4-bbd567c0041f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encapsulating the image into another dimension (list) because the CNN expects a batch of images\n",
    "# The 0 stnads for the axis where the extra dimension will be added\n",
    "yhat = model.predict(np.expand_dims(resized_image/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e50e3-06c1-4f36-a8c5-940d149fd316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4952e28-d83e-4dc1-98f8-5e9afd881b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def happy_or_sad(yaht):\n",
    "    if yhat > 0.5:\n",
    "        print(\"Predicted class is Calm\")\n",
    "    else:\n",
    "        print(\"Predicted class is Angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e9abe-448c-4d68-b0fc-a54dda8a126f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "happy_or_sad(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfc231-7d2d-4a4b-8595-13a84a3d3009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('angrytest.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7478353-66e7-4044-930a-9ec1c333d9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resized_image = tf.image.resize(img, (256, 256))\n",
    "plt.imshow(resized_image.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895da8e-0241-4c56-aef3-72df77353f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resized_image/255, 0))\n",
    "print(yhat)\n",
    "happy_or_sad(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c9670-66be-4825-97c6-ea26e8624447",
   "metadata": {},
   "source": [
    "## 5. Save the Model\n",
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91af90-696c-4dac-a9ee-19728751d016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f1edb-8db9-43dc-9048-1517e20c2596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join('models', 'calmangrymodel.h5')) # save the model in models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bba63-3e3c-4580-8e61-e7a0fd621e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models', 'calmangrymodel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdc354-8136-4161-96d0-a9df33dd60bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_new = new_model.predict(np.expand_dims(resized_image/255, 0))\n",
    "happy_or_sad(yhat_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in",
   "language": "python",
   "name": "in"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
